ما یک dataset از سناریوهای شبکه داشتیم که برای هر متن، یک لیست triple (spo_list) شامل subject و object مثل bandwidth/latency/ip/protocol داشت. فایل‌ها multi-json بودن و بعضی annotationها داخل متن پیدا نمی‌شدن، پس اول داده رو پاکسازی کردیم و به JSONL استاندارد تبدیل کردیم.
بعد از روی spo_list، دیتاست NER با برچسب‌های BIO ساختیم (tokens + ner_tags). سپس یک مدل Transformer (DistilBERT) برای NER آموزش دادیم که F1 حدود 0.99 گرفت و entityهای مهم رو دقیق استخراج می‌کنه.
در مرحله بعد entityها رو به یک قالب Intent قابل استفاده تبدیل کردیم (مثلاً bandwidth/latency/ip/protocol).
همزمان یک classifier سبک با TF-IDF + Logistic Regression هم ساختیم که slice_type را با دقت حدود 0.99 پیش‌بینی می‌کند.
در نهایت یک دمو end-to-end داریم که از متن خام، هم entityها و template را می‌دهد و هم slice مناسب را پیشنهاد می‌کند.»


0) مسئله‌ی اصلی چی بود؟
فرض کن یک نفر به شبکه می‌گه:
«برای سرویس ویدیو، از HTTP/HTTPS استفاده کن، تاخیر کمتر از 90ms باشه، IP سرور 10.0.2.52، و packet loss کمتر از 0.05%.»
این یک درخواست انسانیه. کامپیوتر باید بفهمه “چی می‌خواد”:
•	سرویس چیه؟
•	پروتکل چیه؟
•	تاخیر چقدر؟
•	IP کجاست؟
•	نرخ packet loss چقدره؟
•	و در آخر این درخواست مناسب کدوم نوع سرویس شبکهه (URLLC/eMBB/mMTC)؟
پروژه‌ی تو دقیقاً همین کار رو انجام می‌ده:
متن → اطلاعات مهم → یک خلاصه‌ی ساختاریافته → پیشنهاد نوع سرویس (slice).
________________________________________
1) داده‌هایی که دانلود کردی چی بودن؟
تو ۴ تا فایل داشتی: engin.json / sichuan.json / docu.json / volu.json
هرکدوم شامل کلی “نمونه” بودن. هر نمونه یک چیز داشت:
1.1 text یعنی چی؟
text همون جمله/پاراگراف انگلیسیه که درخواست رو توصیف می‌کنه.
مثال واقعی از دیتای تو:
•	text = "Allocate 20Mbps bandwidth to the e-commerce platform ... latency ... IP ..."
1.2 slice_type یعنی چی؟
slice_type یعنی نوع دسته‌بندی سرویس شبکه که داده بهش می‌چسبونه:
•	URLLC (برای کارهایی که خیلی حساس به تاخیرند)
•	eMBB (برای سرویس‌های سنگین مثل ویدئو/استریم)
•	mMTC (برای تعداد زیاد دستگاه/کارهای IoT)
فعلاً لازم نیست مفهوم شبکه‌ای عمیقش رو بدونی؛ فقط بهش مثل “کلاس” یا “نوع” نگاه کن.
1.3 spo_list یعنی چی؟
این مهم‌ترین بخشه.
spo_list یعنی یک لیست از چند “رابطه/اطلاعات استخراج‌شده” از متن.
هر آیتم داخل spo_list یک بسته اطلاعاتیه که می‌گه:
•	subject: “کی/چی” داریم درباره‌اش حرف می‌زنیم
•	predicate: “چه رابطه‌ای” یا “چه کاری” انجام می‌شه
•	object: “مقدار/چیز مرتبط” که به subject مربوطه
این دقیقاً همون چیزیه که من بهش گفتم triple (سه‌تایی).
مثال از خروجی تو (همون id=2 که قبلاً فرستادی):
•	subject = E-commerce
•	predicate = allocate bandwidth
•	object = 20Mbps
یعنی: «برای E-commerce مقدار bandwidth برابر 20Mbps در نظر بگیر»
یکی دیگه:
•	subject = E-commerce
•	predicate = ensure latency
•	object = 90ms
یعنی: «تاخیر برای E-commerce باید 90ms باشه»
پس spo_list عملاً یه راهه که داده به ما می‌گه “تو این متن چه چیزهایی مهمه”.
________________________________________
2) Entity یعنی چی؟
Entity یعنی “چیز مهم داخل متن” که باید از متن پیدا کنیم.
مثل:
•	20Mbps (یک entity از نوع bandwidth)
•	90ms (یک entity از نوع latency)
•	10.0.1.95 (یک entity از نوع ip address)
•	VPN (entity از نوع protocol)
•	teacher یا e-commerce یا streaming media service (subjectهای اصلی)
پس Entity = قطعه‌های مهم اطلاعات داخل جمله.
________________________________________
3) NER یعنی چی؟
NER مخفف Named Entity Recognition ـه.
ولی به زبان ساده:
NER یعنی سیستم یاد بگیره تو متن، اون entityها رو پیدا کنه و برچسب بزنه.
مثلاً تو جمله:
“Allocate 20Mbps bandwidth … latency 90ms … ip 10.0.1.95”
NER باید تشخیص بده:
•	20Mbps → bandwidth
•	90ms → latency
•	10.0.1.95 → ip address
•	e-commerce → subject (کسی که درخواست درباره‌اشه)
________________________________________
4) پس ما دقیقاً چی کار کردیم؟ مرحله به مرحله
مرحله A) مشکل اول: فایل‌ها JSON “معمولی” نبودن
تو اول خطای Extra data گرفتی.
معنیش چی بود؟
یعنی فایل مثل این نبود:
[ { ... }, { ... }, { ... } ]
بلکه مثل این بود:
{ ... }
{ ... }
{ ... }
چندتا آبجکت پشت هم.
پس ما مجبور شدیم یک روش خواندن مخصوصش بنویسیم.
نتیجه: فایل‌ها رو درست خوندیم.
________________________________________
مرحله B) پاکسازی (چرا لازم بود؟)
گاهی داخل spo_list چیزهایی بود که واقعاً تو متن پیدا نمی‌شدن یا خراب بودن.
مثلاً object نوشته “X” ولی تو متن اصلاً X وجود نداره.
اگر این‌ها رو نگه می‌داشتیم، مدل گیج می‌شد.
پس 01_clean_to_jsonl.py این کارها رو کرد:
•	هر رکورد رو خواند
•	هر SPO (سه‌تایی) رو چک کرد: آیا subject/object تو متن دیده می‌شود؟
•	اگر نه، حذفش کرد
•	بعضی IPهای placeholder رو از خود متن پیدا کرد و درست کرد
•	خروجی تمیز را در قالب استاندارد JSONL ذخیره کرد
خروجی این مرحله:
data/processed/*.cleaned.jsonl
________________________________________
مرحله C) تبدیل spo_list به دیتای آموزشی NER
اینجا مهمه:
ما می‌خواستیم مدل یاد بگیره خودش entityها رو پیدا کنه.
اما داده‌ی ما entity آماده نداشت، فقط spo_list داشت.
پس 02_build_ner_dataset.py این کار رو کرد:
1.	متن را به تکه‌های کوچک تقسیم کرد (اسمش توکنه، یعنی “کلمات و عددها و علائم”)
o	مثال: "10.0.1.95" یک تکه
o	"20Mbps" یک تکه
o	"e-commerce" یک تکه
2.	بعد برای هر SPO:
o	subject رو در متن پیدا کرد
o	object رو در متن پیدا کرد
3.	روی توکن‌ها برچسب گذاشت: اینجا می‌رسیم به BIO.
________________________________________
5) BIO یعنی چی؟
BIO فقط یک روش برچسب‌زدن روی کلمات است.
•	B- یعنی “شروع یک entity”
•	I- یعنی “ادامه همان entity”
•	O یعنی “هیچ چیز مهمی نیست”
مثال:
اگر entity = “streaming media service” باشد و متن 3 کلمه داشته باشد:
•	streaming → B-SUBJ_ONLINE_SERVICE
•	media → I-SUBJ_ONLINE_SERVICE
•	service → I-SUBJ_ONLINE_SERVICE
اگر کلمه‌ای بی‌ربط باشد:
•	the → O
•	is → O
پس BIO یعنی: هر کلمه مشخص می‌کند جزو کدام entity هست یا نیست.
________________________________________
6) آموزش مدل یعنی چی؟ (خیلی ساده)
آموزش یعنی:
ما هزاران مثال به مدل نشان دادیم:
•	این متن
•	این برچسب‌ها (BIO)
مدل یاد گرفت وقتی جمله مشابه دید، خودش تشخیص بده کدام تکه‌ها bandwidth/latency/ip/protocol هستند.
نتیجه مدل NER:
وقتی یک متن جدید دادی، دقیقاً همان entityها را پیدا کرد (دیدی که درست درآورد).
________________________________________
7) چرا Template ساختیم؟
Entityها به تنهایی لیست‌اند و کمی شلوغ‌اند.
Template یعنی:
«بیا این entityها رو تو یک فرم مرتب بریزیم تا آدم و سیستم راحت استفاده کنن.»
مثلاً این:
•	user: teacher
•	service: VoIP
•	protocol: VPN
یا:
•	business: e-commerce
•	bandwidth: 20Mbps
•	latency: 90ms
•	ip: 10.0.1.95
این همون خروجی 05_intent_template.py بود.
________________________________________
8) تشخیص slice_type یعنی چی؟
این قسمت مثل “حدس دسته” است.
از روی متن، مدل دوم می‌گه این درخواست بیشتر شبیه:
•	URLLC
•	یا eMBB
•	یا mMTC
تو این کار رو با یک مدل ساده انجام دادی (نه Transformer):
•	متن را تبدیل به ویژگی کرد (TF-IDF یعنی “کلمات مهم”)
•	بعد LogisticRegression یاد گرفت از روی این ویژگی‌ها کلاس را حدس بزند
نتیجه: Accuracy ≈ 0.99
________________________________________
9) در نهایت چه چیزی تحویل داریم؟
دموی نهایی (07_demo_pipeline.py) دقیقاً این کار را می‌کند:
ورودی: یک متن
خروجی:
1.	Entityها (همون چیزهای مهم)
2.	Template مرتب‌شده
3.	Slice پیشنهادی
________________________________________

نسخه ی ساده:
«ما یک سری متن انگلیسی داشتیم که درخواست‌های شبکه رو توضیح می‌داد. داده همراهش لیستی از اطلاعات مهم مثل bandwidth، latency، IP و protocol داشت.
اول داده رو تمیز کردیم چون بعضی برچسب‌ها داخل متن وجود نداشت.
بعد از روی همین اطلاعات، یک دیتاست ساختیم که به هر کلمه می‌گفت آیا جزء یک اطلاعات مهم هست یا نه.
بعد یک مدل آموزش دادیم که وقتی متن جدید می‌بیند خودش اطلاعات مهم را از متن استخراج کند.
سپس این اطلاعات را به یک فرم مرتب تبدیل کردیم (template).
در نهایت یک مدل جدا هم ساختیم که از روی متن، نوع سرویس مناسب (URLLC/eMBB/mMTC) را پیشنهاد دهد.
دموی نهایی هم نشان می‌دهد که سیستم از متن خام تا خروجی نهایی را خودکار انجام می‌دهد.»


1) برای “ترین کردن NER” از چه مدلی استفاده شد و چرا؟
مدل: DistilBERT (distilbert-base-uncased)
این مدل چیه؟
یه مدل آماده‌ی زبانیه که قبلاً روی حجم خیلی زیاد متن انگلیسی یاد گرفته “زبان رو بفهمه”. ما ازش استفاده کردیم تا یک کار مشخص انجام بده: پیدا کردن چیزهای مهم داخل جمله.
NER یعنی چی؟
NER یعنی: توی متن، قسمت‌های مهم رو پیدا کن و اسم‌گذاری کن.
مثلاً تو جمله:
•	20Mbps → پهنای‌باند
•	90ms → تاخیر
•	10.0.1.95 → IP
•	VPN → پروتکل
چرا DistilBERT؟
•	سبک‌تر و سریع‌تر از BERT کامل (روی CPU هم قابل اجراست)
•	چون از قبل “زبان” رو بلده، با دیتای تو سریع خوب یاد می‌گیره
•	برای پروژه‌های دانشگاهی، یک baseline خیلی استاندارد و قابل دفاعه
پس: DistilBERT رو آموزش دادیم که روی هر کلمه/تکه‌ی جمله تصمیم بگیره “این entity هست یا نیست و از چه نوعی؟”
________________________________________
2) برای “تشخیص slice_type” از چه کلاسیفایری استفاده شد و چرا؟
کلاسیفایر: Logistic Regression روی ویژگی‌های TF-IDF
کلاسیفایر یعنی چی؟
یعنی یک مدل تصمیم‌گیر که می‌گه این متن به کدوم دسته می‌خوره.
اینجا دسته‌ها چی بودن؟
URLLC / eMBB / mMTC
TF-IDF یعنی چی؟ (خیلی ساده)
یعنی متن رو تبدیل کنیم به یک لیست از “کلمات مهم”.
کلماتی مثل latency, packet loss, streaming, bandwidth برای مدل مهم می‌شن.
چرا Logistic Regression؟
•	خیلی سریع و سبک
•	برای دسته‌بندی متن با TF-IDF معمولاً خیلی خوب جواب می‌ده
•	خروجی‌اش قابل گزارش و دفاعه (به‌خصوص برای baseline)
پس: این مدل فقط از روی “متن” حدس می‌زنه این درخواست بیشتر مناسب کدوم slice هست.
________________________________________
3) مثال “تصویری” (کاملاً قابل فهم)
بیایم همین جمله‌ی سوم که تست کردی رو به شکل تصویری باز کنیم:
ورودی (Text)
Provide streaming media service through HTTP/HTTPS protocol,
latency less than 90ms, Sip server ip address is 10.0.2.52,
call packet loss rate is kept below 0.05%.
________________________________________
مرحله 1: خروجی NER (Entity Extraction)
مدل NER این “چیزهای مهم” رو از متن بیرون کشید:
تکه‌ی پیدا شده در متن	معنی ساده	برچسبی که مدل داد
streaming media service	سرویس/کسب‌وکار اصلی	SUBJ_ONLINE_SERVICE
HTTP/HTTPS	پروتکل	OBJ_PROTOCOL
90ms	تاخیر	OBJ_LATENCY
10.0.2.52	IP سرور	OBJ_IP_ADDRESS
0.05%	نرخ packet loss	OBJ_PACKET_LOSS_RATE
اگر بخوام “هایلایت‌شده” نشون بدم:
Provide [streaming media service] through [HTTP/HTTPS] protocol,
latency less than [90ms], server ip address is [10.0.2.52],
packet loss rate below [0.05%].
________________________________________
مرحله 2: ساخت Template (فرم مرتب)
بعد 05_intent_template.py اینا رو ریخت تو یک فرم تمیز:
{
  "user": null,
  "business_or_service": "streaming media service",
  "protocol": ["HTTP/HTTPS"],
  "latency": "90ms",
  "ip_address": ["10.0.2.52"],
  "packet_loss_rate": "0.05%"
}
یعنی سیستم داره می‌گه:
•	موضوع: سرویس استریم
•	پروتکل: HTTP/HTTPS
•	شرط‌ها: تاخیر 90ms، packet loss 0.05%، IP مشخص
________________________________________
مرحله 3: پیش‌بینی Slice Type (کلاسیفایر)
همین متن رفت تو کلاسیفایر و گفت:
SLICE_PRED: eMBB
یعنی:
•	این درخواست بیشتر شبیه سرویس‌های سنگین و پهنای‌باندی (مثل ویدئو/استریم) است.
________________________________________
جمع‌بندی خیلی ساده (یک خطی)
•	DistilBERT رو آموزش دادیم تا از متن اطلاعات مهم رو پیدا کنه (NER)
•	TF-IDF + LogisticRegression رو ساختیم تا از روی متن نوع slice رو حدس بزنه
•	در نهایت یک دمو داریم: متن → entityها → template → slice


1) این مقاله دقیقاً چی می‌گه؟ (ایده اصلی)
اسم مقاله: Business Intent and Network Slicing Correlation Dataset (BINS)
ایده اصلیش اینه:
•	توی شبکه‌های مدرن، آدم‌ها (یا سازمان‌ها) به‌جای کانفیگ کردن دستی شبکه، نیّت‌شون رو با زبان طبیعی می‌گن (مثلاً: «برای ویدئوکنفرانس تأخیر کم باشه»).
•	سیستم‌های جدیدی هستن به اسم Intent-Based Networking (IBN) که این “نیّت” رو می‌فهمن و خودشون شبکه رو تنظیم می‌کنن.
•	مشکل بزرگ: دیتاست عمومیِ کافی برای آموزش مدل‌های فهمِ نیّت شبکه‌ای کم داریم.
•	این مقاله میاد یک دیتاست بزرگ و ساختارمند معرفی می‌کنه که:
1.	متن نیّت‌ها (جملات واقعی/شبیه‌سازی‌شده) رو داره
2.	روی متن‌ها برچسب موجودیت‌ها و روابط زده
3.	بین «نیّت کسب‌وکار» و «نوع network slice» هم ارتباط گذاشته 

________________________________________
2) قبل از صفحه‌به‌صفحه: چند تا مفهوم کلیدی رو خیلی ساده کنیم
Intent-Based Networking (IBN) یعنی چی؟
یعنی به شبکه می‌گی «چی می‌خوای»، نه «چجوری انجام بده».
مثل اینکه به جای اینکه بری توی روترها ۱۰۰ تا دستور بزنی، بگی:
•	«برای دانشجوها اینترنت پایدار باشه»
•	«برای بازی latency پایین باشه»
و سیستم خودش سیاست‌ها و تنظیمات رو تولید کنه. 

Network Slicing یعنی چی؟
تصور کن یک شبکه فیزیکی داری، ولی اون رو به چند «شبکه مجازی تخصصی» تقسیم می‌کنی.
هر slice برای یک نوع سرویس: مثلا یکی برای ویدئو (پهنای باند بالا)، یکی برای کنترل صنعتی (تاخیر خیلی کم).
NER و BIO یعنی چی؟
•	NER (Named Entity Recognition): از داخل یک جمله، «چیزهای مهم» رو بیرون می‌کشه و برچسب می‌زنه (مثل کاربر، سرویس، پهنای باند، latency، دستگاه…). 

•	BIO tagging: برای هر کلمه مشخص می‌کنه:
o	B = شروع یک موجودیت
o	I = ادامه موجودیت
o	O = بیرون از موجودیت
این قالب استاندارد دیتاست‌های NERه. 

________________________________________
3) توضیح صفحه‌به‌صفحه (همراه معنی بخش‌ها و اصطلاحات)
صفحه 1 — چکیده و انگیزه
اینجا خیلی مستقیم می‌گه:
•	IBN مهمه چون شبکه‌ها پیچیده‌تر شدن و می‌خوایم خودکار اداره بشن.
•	برای اینکه سیستم “نیّت” رو بفهمه، نیاز به دیتاست هست.
•	این مقاله دیتاست BINS رو معرفی می‌کنه: متن نیّت‌ها + برچسب‌ها + ارتباط با slice. 

بعد توی Background می‌گه چرا «دیتا محور شدن» آینده شبکه‌ست و بدون داده، سیستم‌های حلقه‌بسته/خودکار تصمیم درست نمی‌گیرن. 

________________________________________
صفحه 2 — مسئله دقیق‌تر و اینکه دیتاست از کجا اومده
اینجا سه تا مشکل اصلی رو می‌گه:
1.	برای intent recognition باید «موجودیت‌های مناسب» تعریف کنی (چی‌ها توی متن مهمن). 

2.	دیتای برچسب‌خورده کم داریم، چون شرکت‌ها معمولاً داده واقعی رو نمی‌دن و دیتاهای عمومی هم سریع قدیمی می‌شن. 

3.	ساخت network slice باید واقعاً با نیاز کسب‌وکار align باشه، نه فقط انتخاب از چند مدل ثابت. 

بعد می‌گه دیتاست BINS از سه کانال ساخته شده:
•	داده واقعی اپراتور (China Telecom Sichuan)
•	داده ساخت مهندس‌های شبکه + کاربران شبیه‌سازی‌شده
•	داده استخراج‌شده از مقالات/استانداردها/وب‌سایت‌ها 

و یک عدد مهم هم می‌ده: بیش از 100,000 entity و بیش از 40,000 triple (برای ساخت گراف دانش). 

Triple یعنی چی؟
یعنی مثل (موضوع، رابطه، مفعول)
مثلا: (سرویس ویدئوکنفرانس، نیازمند است، latency کم)
________________________________________
صفحه 3 — جمع‌آوری نیّت با “voice assistant”
اینجا می‌گه یک سری داوطلب رو آوردن که با یک سیستم دستیار صوتی تعامل کنن و نیازهای شبکه‌ای رو با صدا بگن؛ بعد با Google Speech-to-Text تبدیلش کردن به متن. 

نکته مهمش برای تو:
•	این یعنی دیتاست فقط “جمله‌های کتابی” نیست؛ بخشی ازش شبیه ورودی واقعی آدم‌هاست.
________________________________________
صفحه 4 — “قالب استاندارد نیّت” و موجودیت‌ها
این صفحه خیلی کلیدیه چون تعریف می‌کنه توی هر intent چه چیزهایی رو برچسب می‌زنن. لیست entity labelها:
•	Intent user: چه کسی درخواست داده (دانشجو، ادمین، شرکت…) 

•	Network action: شبکه باید چی کار کنه (provide service، limit bandwidth، self-healing…) 

•	Intent target: هدف/سرویس (web browsing، online education، video conf…) 

•	Target device/function (اختیاری): دستگاه یا فانکشن (router، resource sharing…) 

•	Network performance (اختیاری): معیارهای شبکه (bandwidth, latency, jitter…) 

•	Lifecycle (اختیاری): این نیّت تا کی معتبره (۶ ساعت، یک روز…) 

بعد مثال می‌زنه که حتی می‌تونی بعضی از این‌ها رو نگفتی و باز هم intent معتبره. 

________________________________________
صفحه 5 — پاکسازی داده و Annotation
اینجا می‌گه چون داده از چند جا جمع شده، نویز زیاد داره. چه نویزهایی؟
•	جملات تکراری با بیان متفاوت (semantic repetition) 

•	کاراکترهای عجیب (Non-ASCII) 

•	غلط املایی (با PySpellChecker درستش کردن) 

•	اطلاعات حاشیه‌ای نامرتبط (اول جمله رو می‌ندازی دور، “intent core” رو نگه می‌داری) 

بعد می‌گه روی دیتا سه نوع برچسب می‌زنن:
1.	entity annotation
2.	relationship annotation
3.	slice type annotation (نوع slice) 

و تاکید می‌کنه BIO هم به‌عنوان قالب استاندارد NER استفاده شده. 

________________________________________
صفحه 6 — فایل‌های دیتاست دقیقاً چیه؟
دیتاست روی figshare هست و ساختار پوشه‌ای داره: raw (CSV) و labeled (JSON). 

فایل‌های مهم:
•	Raw intent data: engin_ori.csv و volu_api.csv و همچنین docu.csv و sichuan.csv 

•	Labeled data (JSON): engin.json, volu.json, docu.json, sichuan.json 


هر رکورد شامل متن + entityها + relationshipها + slice type + BIO هست. 

________________________________________
صفحه 7 — اعتبارسنجی فنی (Technical Validation) یعنی چی؟
این بخش می‌گه: «اوکی دیتاست داریم؛ از کجا معلوم خوبه؟»
دو کار کرده:
1.	با ابزار DataProfiler کیفیت داده رو سنجیده (سازگاری، تکراری نبودن، کامل بودن). 

2.	با مدل‌های NER واقعی تست کرده که آیا می‌شه روش مدل آموزش داد یا نه. 

مدل‌هایی که تست کرده:
•	BERT-CRF
•	BERT-BiLSTM-CRF
•	و یک مدل جدیدتر: DeBERTa-v3-large (با فاین‌تیون در spaCy) 

خیلی ساده: CRF اینجا چی کار می‌کنه؟
وقتی داری به کلمه‌ها برچسب BIO می‌زنی، بعضی برچسب‌ها “کنار هم” معنی ندارن (مثلاً I بدون B). CRF کمک می‌کنه مدل، توی خروجی یک توالی منطقی بسازه. 

________________________________________
صفحه 8 — نتایج عددی (F1 و …)
اینجا می‌گه:
•	BERT-BiLSTM-CRF بهتر از BERT-CRF بوده (کنتکست بهتر). 
•	DeBERTa-v3-large از همه بهتر بوده. 
جدول عملکرد (خلاصه‌ی معنی‌دارش):
•	روی engin.json حدوداً F1 نزدیک 0.94 برای DeBERTa و ~0.92 برای BERT-BiLSTM-CRF گزارش شده. 
________________________________________
4) جمع‌بندی خیلی کاربردی برای ارائه/امتحان
1.	این مقاله یک دیتاست به نام BINS معرفی می‌کند که جملات نیّت شبکه‌ای را همراه با برچسب موجودیت/رابطه/BIO و همچنین نوع network slice ارائه می‌دهد. 
2.	دیتا از سه منبع ساخته شده: اپراتور واقعی + ساخت مهندس/کاربر شبیه‌سازی‌شده + استخراج از اسناد و مقالات. -
3.	کیفیت دیتاست با ابزار DataProfiler و با آموزش مدل‌های NER (BERT-CRF / BERT-BiLSTM-CRF / DeBERTa) سنجیده شده و نتایج F1 بالا نشان می‌دهد دیتاست برای Intent Recognition قابل استفاده است.-
